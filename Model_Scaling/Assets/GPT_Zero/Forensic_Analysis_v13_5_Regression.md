# Forensic Analysis: The 100% Regression (Evasion 6.1)

**Date**: 2025-12-19
**Verdict**: 100% AI (High Confidence)
**Strategy**: Semantic De-Optimization (Simplification)

## 1. The Perplexity Trap
We replaced high-entropy tokens (Academic Nouns) with low-entropy tokens (Simple Verbs). 
- *Result*: The text became "Smoothly Simple."
- *AI Consequence*: Low perplexity + perfect grammar = 100% AI. 
- *Insight*: **AI writes "Simple" better than it writes "Complex."** Dumbing it down made it look *more* like an AI trying to explain something.

## 2. The Green Highlight (Paraphrasing)
The screenshot shows "AI Paraphrasing" flags.
- This confirms that GPTZero v3.15b maps the *semantic density* of the simplified text directly to the original source.
- Because we removed the "Noise" (Logic Shattering) in favor of "Simplification," the *linear logic* returned.

## 3. The Pivot: Evasion 6.2 "Additive Complexity"
We must go the OTHER way. We need **High Perplexity**.
- Instead of removing words, we must ADD words that *do not exist* in the prompt.
- **Micro-Tripping**: Add irrelevant details, personal anecdotes, or specific metaphors.
- **Revert**: Go back to the Logic Shattering structure (which gave us 57%) but infuse it with *specific, unnecessary complexity*.

## 4. New Rule: "The Tangent"
A human draft often goes off-track.
- *Prompt*: "Mention a specific (invented) detail about the cafe setting, or a personal annoyance, then link it back."
- *Goal*: Break the semantic map by introducing nodes that have NO origin in the source text.
