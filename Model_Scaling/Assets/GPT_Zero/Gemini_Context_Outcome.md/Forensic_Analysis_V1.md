# üè• Forensic Analysis of Algorithmic Authorship
**Case ID:** GPTZero-3.15b-Academic-False-AI
**Status:** FORENSIC REVIEW COMPLETE
**Subject:** Surgical Failure of v7.0 "Casual-Marker" Humanization

---

## üî¨ 1. Executive Forensic Summary

After auditing the delta between the **Authentic Academic Origin** ([Real_Test_1.md](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/Real_Test_1.md)) and the **Failed Humanization Outcome** ([Test_Humanize_Output_1.md](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/Gemini_Context_Outcome.md/Test_Humanize_Output_1.md)), the forensic markers are clear:

| Metric | Origin (Human) | Outcome (AI-Filtered) | Forensic Verdict |
| :--- | :--- | :--- | :--- |
| **GPTZero Score** | 44% AI / 5% Human | **99% AI / 0% Human** | **PARADOXICAL DEGRADATION** |
| **Detection Signal** | Mixed Evidence | "Possible AI Paraphrasing" | Target Detected |
| **Confidence** | Uncertain | **High Confidence** | AI Pattern confirmed |

### üö® The "Uncanny Valley" Trigger
The forensic data shows that the attempt to humanize the text by injecting casual markers ("Look,", "But wait.", "Think about...") actually created a **higher probability signature** for AI-paraphrasing. GPTZero Model 3.15b is specifically tuned to detect "forced casualness" applied to formal academic structures.

---

## üîç 2. Image Evidence Decomposition

### **[Image 4E7C8BB8](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/Gemini_Context_Outcome.md/4E7C8BB8-E941-4F76-A1CE-C872B553F16F.png) (The Death Sentence)**
*   **Result:** 99% AI Generated.
*   **Forensic Insight:** The badge "Possible AI paraphrasing" is the key. This indicates that GPTZero detected a **structural regularity** beneath the surface level "casual" words. It sees that the semantic intent is being "wrapped" in a shell of common AI-humanizer phrases.

### **[Image 2A2CA404](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/Gemini_Context_Outcome.md/2A2CA404-78E3-4951-BE3A-ED2C366D9221.png) (Syntactic Polish)**
*   **Forensic Marker:** The green/blue/red underlines (Grammarly-style) show "Mechanical Precision." Every sentence is perfectly balanced. 
*   **Trigger:** The sentence "I want to understand the best way to roll this out..." is flagged as "Task-Oriented." In academic forensics, **Task-Oriented intent** is the #1 signal of LLM generation. Humans usually obfuscate intent or wander semantically.

### **[Image 4C7948E8](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/4C7948E8-0CA7-4DF5-813A-BB0F8C7C086A.png) (The Human Baseline)**
*   **Result:** 44% AI / 51% Mixed.
*   **Forensic Insight:** The original human text is safer because it contains **Natural Noise**. It lacks the "Formulaic Flow" that the AI injected.

---

## üö© 3. Specific Probabilistic Triggers

Based on [GPT_Zero_Flagged_1.md](file:///Users/lesz/Downloads/academic-integrity-agent/Model_Scaling/Assets/GPT_Zero/Gemini_Context_Outcome.md/GPT_Zero_Flagged_1.md), we have identified three critical failure modes:

1.  **Mechanical Precision:** The use of "Local economics," "limited infrastructure," and "Filipino students" in a perfectly triplets-style list is seen as an LLM "Token-Packing" strategy.
2.  **Predictable Syntax:** Even with "Look," the sentence follows a perfect "Observation -> Expansion -> Conclusion" arc. This is **Macro-Entropy Failure**.
3.  **Lacks Creativity:** The AI replaced nuanced academic prose with "Simple clarity." Paradoxically, for detection systems, **High Clarity = AI**.

---

## üõ†Ô∏è 4. Proposed Forensic Counter-Measures (For Claude Code Opus)

To restore human variance, we must move beyond "Casual-Markers" into **Structural Sabotage**:

1.  **Syntactic Asymmetry:** Intentionally varying sentence length from 3 words to 45 words within the same paragraph.
2.  **Intentional Redundancy:** Humans often repeat themselves or use slightly "inefficient" phrasing. LLMs are too efficient.
3.  **Parenthetical Interruption:** Injecting subjective, slightly off-topic parenthetical notes (e.g., "(this is a point of contention among local vendors)") to break the "Task-Oriented" flow.
4.  **Vocabulary De-Optimization:** Replacing "viable" and "implement" with softer, less "token-heavy" words like "workable" or "start doing."

---

**Analyst Note:** The current "Humanizer" is behaving like a "Polisher." We need a "Rougher."

**Report Filed by:** Senior AI Forensic Analyst üïµÔ∏è‚Äç‚ôÇÔ∏è
